# Ollama Configuration
# No API key needed - Ollama runs locally!

# Make sure Ollama is running:
# 1. Install Ollama from https://ollama.ai
# 2. Pull the model: ollama pull gemma3:4b
# 3. Start Ollama (it runs automatically on http://localhost:11434)

# Optional: Change Ollama URL if running on different host/port
# OLLAMA_URL=http://localhost:11434
